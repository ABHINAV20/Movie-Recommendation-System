{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "dataset_path = \"ml-20m\"\n",
    "\n",
    "ratings_df = pd.read_csv(os.path.join(dataset_path,\"ratings.csv\"), encoding= \"utf-8\", sep=\",\")\n",
    "\n",
    "user_id, movie_id, ratings = list(ratings_df[u'userId']), list(ratings_df[u'movieId']), list(ratings_df[u'rating'])\n",
    "\n",
    "user_ratings_map, user_mean_sd_ratings = defaultdict(dict), defaultdict(float)\n",
    "\n",
    "\n",
    "normalized_ratings = defaultdict(dict)\n",
    "\n",
    "for idx in range(len(user_id)):\n",
    "    user_ratings_map[user_id[idx]][movie_id[idx]] = float(ratings[idx]) \n",
    "    \n",
    "for user_id,movie_rating_map in user_ratings_map.items():\n",
    "    ratings = [r for m,r in movie_rating_map.items()]\n",
    "    mean_r, sd_r = np.mean(ratings),np.std(ratings)\n",
    "    \n",
    "    user_mean_sd_ratings[user_id] = (mean_r, sd_r)\n",
    "        \n",
    "    for movie_id, ratings in movie_rating_map.items():\n",
    "        if (sd_r == 0):\n",
    "            normalized_ratings[user_id][movie_id] = 0.0\n",
    "        else:\n",
    "            normalized_ratings[user_id][movie_id] = float(ratings - mean_r)/sd_r\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df = pd.read_csv(os.path.join(dataset_path, \"tags.csv\"), encoding=\"utf-8\", sep=\",\")\n",
    "\n",
    "genres_df = pd.read_csv(os.path.join(dataset_path, \"movies.csv\"), encoding=\"utf-8\",sep=\",\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "movie_id, tags = list(tags_df[u'movieId']), list(tags_df[u'tag'])\n",
    "\n",
    "tags = [str(tag) for tag in tags]\n",
    "\n",
    "movie_tag_map = defaultdict(list)\n",
    "\n",
    "for idx in range(len(movie_id)):\n",
    "    tag = tags[idx].lower()  \n",
    "    tag = re.sub(\"[^a-zA-Z0-9 ]\", \" \", tag)\n",
    "    tag = tag.strip()\n",
    "    tag = re.sub(\"\\s+\", \" \", tag)\n",
    "        \n",
    "    if (len(tag)>0):\n",
    "        tag_words = tag.split()\n",
    "        tag = \" \".join([x for x in tag_words if x not in stop_words])\n",
    "        \n",
    "        movie_tag_map[movie_id[idx]].append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id, genres = list(genres_df[u'movieId']), list(genres_df[u'genres'])\n",
    "\n",
    "for idx in range(len(movie_id)):\n",
    "    genre = genres[idx].lower()\n",
    "    all_genres = genre.split(\"|\")\n",
    "    \n",
    "    for gen in all_genres:\n",
    "        movie_tag_map[movie_id[idx]].append(gen)\n",
    "        \n",
    "movie_tags = []\n",
    "movie_ids_index = defaultdict(int)\n",
    "movie_ids = [m_id for m_id, _ in movie_tag_map.items()]\n",
    "\n",
    "for idx in range(len(movie_ids)):\n",
    "    m_id = movie_ids[idx]\n",
    "    movie_ids_index[m_id] = idx\n",
    "    movie_tags.append(\"###\".join(movie_tag_map[m_id]))\n",
    "#print(movie_tags)\n",
    "#Create the TF-IDF weighted movie-tag matrix\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda sent: sent.split(\"###\"), ngram_range=(1,1), stop_words='english')\n",
    "# print(vectorizer)\n",
    "movie_tag_mat = vectorizer.fit_transform(movie_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def get_user_model(user_id, user_ratings_map, movie_tag_mat, movie_ids_index):\n",
    "    movie_ids = [m_id for m_id, rating in user_ratings_map[user_id].items() if m_id in movie_ids_index]\n",
    "    movie_ids_rows = [movie_ids_index[m_id] for m_id in movie_ids]\n",
    "    labels = np.array([rating for m_id, rating in user_ratings_map[user_id].items() if m_id in movie_ids_index])\n",
    "    train_data = movie_tag_mat[movie_ids_rows,:]\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(train_data):\n",
    "        X_train, X_test = train_data[train_index], train_data[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        \n",
    "        errors.append(mean_squared_error(y_test, preds))\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(train_data, labels)\n",
    "    \n",
    "    return model, np.mean(errors)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(model, user_id, user_ratings_map, movie_tag_mat, movie_ids_index, num_rec=10):\n",
    "    rated_movie_ids = set([m_id for m_id, _ in user_ratings_map[user_id].items()])\n",
    "    unrated_movie_ids = [m_id for m_id, idx in movie_ids_index.items() if m_id not in rated_movie_ids and m_id in movie_ids_index]\n",
    "    \n",
    "    movie_ids_rows = [movie_ids_index[m_id] for m_id in movie_ids]\n",
    "    test_data = movie_tag_mat[movie_ids_rows,:]\n",
    "    \n",
    "    preds = model.predict(test_data)\n",
    "    preds = sorted(zip(unrated_movie_ids, preds), key=lambda k:-k[1])\n",
    "    \n",
    "    return preds[:min(len(preds), num_rec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "selected_user_ids = [user_id for user_id,rate_map in user_ratings_map.items() if len(rate_map) > 500]\n",
    "selected_user_ids =selected_user_ids[:100]\n",
    "\n",
    "validation_data = []\n",
    "\n",
    "for user_id in selected_user_ids:\n",
    "    movie_ratings_map = user_ratings_map[user_id]\n",
    "    movie_ids = [mid for mid in movie_ratings_map]\n",
    "    \n",
    "    selected_movie_ids = random.sample(movie_ids, int(0.01 * len(movie_ids)))\n",
    "    \n",
    "    for s_id in selected_movie_ids:\n",
    "        validation_data.append((user_id, s_id, user_ratings_map[user_id][s_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()\n",
    "\n",
    "for user_id,movie_id,ratings in validation_data:\n",
    "    user_ratings_map[user_id].pop(movie_id)\n",
    "    \n",
    "for user_id in selected_user_ids:\n",
    "    model,err = get_user_model(user_id,user_ratings_map,movie_tag_mat,movie_ids_index)\n",
    "    models[user_id] = model\n",
    "    #print (user_id,err)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_rating(model, movie_id, movie_tag_mat, movie_ids_index):\n",
    "    test_data = movie_tag_mat[movie_ids_index[movie_id],:]\n",
    "    preds = model.predict(test_data)\n",
    "    \n",
    "    return preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "sums = 0.0\n",
    "\n",
    "for user_id, movie_id, actual_rating in validation_data:\n",
    "    model = models[user_id]\n",
    "    pred_rating = get_predicted_rating(model, movie_id, movie_tag_mat, movie_ids_index)\n",
    "    sums += (pred_rating - actual_rating) ** 2.0\n",
    "    \n",
    "#print (math.sqrt(float(sums)/len(validation_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def user_similarity(user_ratings_1, user_ratings_2):\n",
    "    sum1, sum2, sums = 0.0, 0.0, 0.0\n",
    "    \n",
    "    dist = 0.0\n",
    "    \n",
    "    movies_rated_1 = set([movie_id for movie_id, rating in user_ratings_1.items()])\n",
    "    movies_rated_2 = set([movie_id for movie_id, rating in user_ratings_2.items()])\n",
    "    \n",
    "    common_rated = movies_rated_1.intersection(movies_rated_2)\n",
    "    \n",
    "    if (len(common_rated) > 0):\n",
    "        for movie_id in common_rated:\n",
    "            rating_1, rating_2 = user_ratings_1[movie_id], user_ratings_2[movie_id]\n",
    "            dist += (rating_1 - rating_2) ** 2\n",
    "        \n",
    "        dist /= float(len(common_rated))\n",
    "        \n",
    "        return 1.0 - np.tanh(math.sqrt(2*dist))\n",
    "    \n",
    "    return 0.0\n",
    "        \n",
    "    \n",
    "def get_similar_users(user_id, all_user_ids, normalized_ratings, num_sim=5):\n",
    "    sims = []\n",
    "    \n",
    "    for j in range(len(all_user_ids)):\n",
    "        user_id_1 = all_user_ids[j]\n",
    "        \n",
    "        if(user_id_1 != user_id):\n",
    "            sim = user_similarity(normalized_ratings[user_id_1],normalized_ratings[user_id])\n",
    "            sims.append([user_id_1, sim])\n",
    "            \n",
    "    sims = sorted(sims, key=lambda k:-k[1])\n",
    "    sims = sims[:min(len(sims), num_sim)]\n",
    "    \n",
    "    return sims\n",
    "\n",
    "def get_predicted_rating(user_id,movie_id,normalized_ratings,user_mean_sd_ratings,similar_user_ids):\n",
    "    sims = [sim for similar_user_id, sim in similar_user_ids]\n",
    "    sim_sum = np.sum(sims)\n",
    "    \n",
    "    pred = 0.0\n",
    "    \n",
    "    for similar_uid, sim in similar_user_ids:\n",
    "        if movie_id in normalized_ratings[similar_uid]:\n",
    "            rating = normalized_ratings[similar_uid][movie_id]\n",
    "            pred += (sim * rating)/float(sim_sum)\n",
    "        \n",
    "    return user_mean_sd_ratings[user_id][1] * pred + user_mean_sd_ratings[user_id][0]    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users_ids = [user_id for user_id,_ in user_ratings_map[user_id].items()]\n",
    "\n",
    "sums = 0.0\n",
    "\n",
    "for user_id, movie_id, actual_rating in validation_data:\n",
    "    filtered_user_id = [u_id for u_id in all_users_ids if movie_id in normalized_ratings[u_id]]\n",
    "    similar_user_ids = get_similar_users(user_id, filtered_user_id, normalized_ratings, 3)\n",
    "    \n",
    "    pred_rating = get_predicted_rating(user_id, movie_id, normalized_ratings, user_mean_sd_ratings, similar_user_ids)\n",
    "    \n",
    "    #print (actual_rating, pred_rating)\n",
    "    \n",
    "    sums += (pred_rating - actual_rating) ** 2.0\n",
    "\n",
    "#print (float(sums)/len(validation_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
